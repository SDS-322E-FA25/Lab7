---
title: "Sentiment Analysis"
output: html_document
date: "2025-10-17"
---

# Exercise 1
Load the `tidyverse` and `tidytext` packages. Install and load `gutenbergr`.
```{r}
# Your code goes here
library(tidyverse)
library(tidytext)
library(gutenbergr)

```

Run this code, so that `book` is in your global environment.
```{r}
# Get SMART stop word lexicon
smart_stop_words <- stop_words |> 
  filter(lexicon == "SMART")

# Download the book Frankenstein
book <- gutenberg_download(84) 

# Tidy, tokenize, and remove stop words
book <- book |> 
  mutate(chapter = cumsum(str_detect(text, "^Chapter"))) |> 
  filter(chapter > 0) |> 
  filter(!str_detect(text, "^Chapter")) |> 
  filter(str_detect(text, "[a-zA-Z]+")) |> 
  unnest_tokens(word, text) |> 
  anti_join(smart_stop_words, join_by(word))

```

# Exercise 2
Find the twenty most common words in Frankenstein, that do not appear in the `sentiments` dataset. Are there any in that list that surprise you?
```{r}
# Your code goes here
book |> 
  anti_join(sentiments, join_by(word)) |> 
  count(word, sort = TRUE) |> 
  slice(1:20)
```

What percentage of unique words in `book` do not appear in `sentiments`?
```{r}
# Your code goes here
den <- book |> 
  distinct(word) |> 
  nrow()

num <- book |> 
  distinct(word) |> 
  anti_join(sentiments, join_by(word)) |> 
  nrow()

(num/den) * 100
```

# Exercise 3
In the `book` dataset which spelling of honor is used: honor or honour? **honour**
How many times is that word used in each chapter of the book?

In the `sentiments` dataset which spelling of honor is used: honor or honour? **honor**
Would the sentiment for that word be added to `book`, if `book` and `sentiments` were joined? **No**
```{r}
# Your code goes here
book |> 
  filter(word %in% c("honor", "honour")) |> 
  count(chapter, word)

sentiments |> 
  filter(word %in% c("honor", "honour"))

```

# Exercise 4
Run the code below. What do you notice about the different spellings and verb tenses for the word "agonize"? **agonised in `book` and agonize in `sentiments`**
```{r}
book |> 
  filter(str_detect(word, "agonize") | str_detect(word, "agonise"))

sentiments |> 
  filter(str_detect(word, "agonize") | str_detect(word, "agonise"))

```

# Exercise 5
There are other sentiment lexicons that can be accessed with `tidytext`. This includes the `nrc` and `afinn` lexicons, which are discussed in the following book chapter: https://www.tidytextmining.com/sentiment.

1. What are the unique sentiment values in the `nrc` lexicon?
2. What are the unique sentiment values in the `afinn` lexicon?
3. What function from `tidytext` can you use to access them?
